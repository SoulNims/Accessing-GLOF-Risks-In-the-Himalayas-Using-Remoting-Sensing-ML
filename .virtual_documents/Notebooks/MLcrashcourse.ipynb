














import pandas as pd
import numpy as np



pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 100)
uncleaned_ml_combined=pd.read_csv("../CSVs/uncleaned_ml_combined.csv",index_col=False)


uncleaned_ml_combined.head()



uncleaned_ml_combined.info()


uncleaned_ml_neg=pd.read_csv("../CSVs/uncleaned_ml_neg.csv")
uncleaned_ml_neg.info()


uncleaned_ml_neg_1=pd.read_csv("../CSVs/uncleaned_ml_neg_1.csv")
uncleaned_ml_neg_1.info()


uncleaned_ml_pos=pd.read_csv("../CSVs/uncleaned_ml_pos.csv")





ml_neg_y_drop=uncleaned_ml_neg.drop(columns=['Year_final'])
ml_neg_y_drop


ml_pos_y_drop=uncleaned_ml_pos.drop(columns=['Year_final'])
ml_pos_y_drop


uncleaned_ml_combined=pd.read_csv('../CSVs/uncleaned_ml_combined.csv')
uncleaned_ml_combined.info()


ml_comb_y_drop=uncleaned_ml_combined.drop(columns=['Year_final'])
ml_comb_y_drop.head()


ml_neg_y_drop.to_csv("../CSVs/ml_neg_y_drop.csv",index=False)
ml_pos_y_drop.to_csv("../CSVs/ml_pos_y_drop.csv",index=False)
ml_comb_y_drop.to_csv("../CSVs/ml_comb_y_drop.csv",index=False)


ml_pos_y_drop.isnull().mean()*100


ml_neg_y_drop.isnull().mean()*100


ml_comb_y_drop.isnull().mean()*100


ml_pos_y_drop.head()





# Load Data
df_comb = pd.read_csv("../CSVs/uncleaned_ml_combined.csv")
df_pos = pd.read_csv("../CSVs/uncleaned_ml_pos.csv")
# Complete Case Analysis (CCA)
df_comb = df.dropna()


print(df_comb.shape)
print(df_pos.shape)


df_pos.head()


# Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier


# Load Data
df_comb = pd.read_csv("../CSVs/uncleaned_ml_combined.csv")

# Complete Case Analysis (CCA)
df_comb = df.dropna()

# Features and Target
X = df_comb.drop("GLOF", axis=1)
y = df_comb["GLOF"]

# Preprocessing
# Only one-hot encode Lake_type_simplified,
# all others are numeric (including 0/1 binary flags)
cat_features = ["Lake_type_simplified"]
exclude_cols = cat_features + ["Year_final","Latitude", "Longitude"]
num_features = [col for col in X.columns if col not in exclude_cols]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features)
    ]
)

# Ensemble Creation Function
# Undersample majority class into many subsets, train separate classifiers

def create_ensemble(X_train, y_train, n_models=5, base_model=None):
    """
    Create an ensemble of classifiers with undersampling.
    
    Parameters:
    - X_train, y_train: training data
    - n_models: number of models in ensemble
    - base_model: the classifier to use (e.g., RandomForestClassifier(), LogisticRegression(), XGBClassifier())
    """
    if base_model is None:
        base_model = RandomForestClassifier()  # default

    models = []

    # Split into minority (1) and majority (0)
    X_minority = X_train[y_train == 1]
    y_minority = y_train[y_train == 1]
    X_majority = X_train[y_train == 0]
    y_majority = y_train[y_train == 0]

    for i in range(n_models):
        # Undersample majority class
        X_majority_resampled, y_majority_resampled = resample(
            X_majority, y_majority,
            replace=False,
            n_samples=len(y_minority),
            random_state=i
        )

        # Combine resampled majority + minority
        X_balanced = pd.concat([X_majority_resampled, X_minority])
        y_balanced = pd.concat([y_majority_resampled, y_minority])

        # Clone base_model so each one is fresh
        clf = Pipeline(steps=[
            ("preprocessor", preprocessor),
            ("classifier", clone(base_model).set_params(random_state=i))
            if hasattr(base_model, "random_state") else
            ("classifier", clone(base_model))
        ])

        # Train
        clf.fit(X_balanced, y_balanced)
        models.append(clf)

    return models

from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

# ----------------------------
# Helper: Ensemble Prediction
# ----------------------------
def ensemble_predict(models, X):
    preds = np.array([m.predict(X) for m in models])
    # Majority vote: if at least half the models predict 1, label as 1 (else 0)
    final_preds = (np.sum(preds, axis=0) >= (len(models) / 2)).astype(int)
    return final_preds






# ----------------------------
# Train-Test Split
# ----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ----------------------------
# Random Forest Ensemble
# ----------------------------
rf_models = create_ensemble(
    X_train, y_train, n_models=5,
    base_model=RandomForestClassifier()
)
evaluate_ensemble("Random Forest", rf_models, X_test, y_test)


# ----------------------------
# Logistic Regression Ensemble
# ----------------------------
lr_models = create_ensemble(
    X_train, y_train, n_models=5,
    base_model=LogisticRegression(max_iter=1000)
)
evaluate_ensemble("Logistic Regression", lr_models, X_test, y_test)


# ----------------------------
# XGBoost Ensemble
# ----------------------------
xgb_models = create_ensemble(
    X_train, y_train, n_models=5,
    base_model=XGBClassifier(
        eval_metric="logloss"
    )
)
evaluate_ensemble("XGBoost", xgb_models, X_test, y_test)





import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay

# ================================
# ROC Curve for Ensemble
# ================================
y_probas = np.mean([m.predict_proba(X_test)[:, 1] for m in ensemble_models], axis=0)

RocCurveDisplay.from_predictions(y_test, y_probas)
plt.title("ROC Curve - Ensemble (Undersampling + RF)")
plt.show()

# ================================
# Feature Importances (average across ensemble)
# ================================
# Extract feature names (numeric + one-hot-encoded categorical)
ohe = ensemble_models[0].named_steps["preprocessor"].named_transformers_["cat"]
cat_feature_names = ohe.get_feature_names_out(cat_features)
all_feature_names = num_features + list(cat_feature_names)

# Collect feature importances from each RandomForest in ensemble
importances_list = []
for model in ensemble_models:
    rf = model.named_steps["classifier"]
    importances_list.append(rf.feature_importances_)

# Average feature importances
avg_importances = np.mean(importances_list, axis=0)

# Sort features by importance
indices = np.argsort(avg_importances)[::-1]
sorted_features = [all_feature_names[i] for i in indices]

# Plot feature importances
plt.figure(figsize=(10,6))
plt.bar(range(len(avg_importances)), avg_importances[indices])
plt.xticks(range(len(avg_importances)), sorted_features, rotation=90)
plt.title("Average Feature Importances Across Ensemble")
plt.tight_layout()
plt.show()




# choose which to drop
drop_cols = ["Latitude", "Longitude", "Year_final"]  # try with/without Year_final
keep_cols = [c for c in X.columns if c not in drop_cols]


X2 = X[keep_cols]
num2 = X2.select_dtypes(include=[np.number]).columns.tolist()
cat2 = X2.select_dtypes(include=["object","category"]).columns.tolist()

prep2 = ColumnTransformer([
    ("num", StandardScaler(), num2),
    ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat2),
])

# quick single-model baseline with class_weight (faster than redoing the whole ensemble)
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

X2_train, X2_test, y2_train, y2_test = train_test_split(
    X2, y, test_size=0.2, stratify=y, random_state=42
)

rf2 = Pipeline([
    ("prep", prep2),
    ("rf", RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42, class_weight="balanced"))
])
rf2.fit(X2_train, y2_train)
auc_drop = roc_auc_score(y2_test, rf2.predict_proba(X2_test)[:,1])
print("AUC with Lat/Long(+Year_final) DROPPED:", round(auc_drop,3))



# ================================
# Imports
# ================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.utils import resample
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

# ================================
# Load Data + CCA
# ================================
df = pd.read_csv("../CSVs/uncleaned_ml_combined.csv")
df = df.dropna()

X = df.drop("GLOF", axis=1)
y = df["GLOF"]

# ================================
# Helper: Preprocessor
# ================================
def make_preprocessor(X):
    cat_features = ["Lake_type_simplified"]
    num_features = [c for c in X.columns if c not in cat_features]
    return ColumnTransformer([
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_features)
    ]), num_features, cat_features

# ================================
# Helper: Ensemble RF with undersampling
# ================================
def create_ensemble(X_train, y_train, preprocessor, n_models=5):
    models = []
    X_minority = X_train[y_train == 1]
    y_minority = y_train[y_train == 1]
    X_majority = X_train[y_train == 0]
    y_majority = y_train[y_train == 0]

    for i in range(n_models):
        # undersample majority
        X_majority_res, y_majority_res = resample(
            X_majority, y_majority,
            replace=False,
            n_samples=len(y_minority),
            random_state=i
        )
        X_bal = pd.concat([X_majority_res, X_minority])
        y_bal = pd.concat([y_majority_res, y_minority])

        rf = RandomForestClassifier(n_estimators=300, random_state=i, n_jobs=-1)
        clf = Pipeline([("prep", preprocessor), ("rf", rf)])
        clf.fit(X_bal, y_bal)
        models.append(clf)
    return models

def ensemble_predict(models, X):
    preds = np.array([m.predict(X) for m in models])
    return (np.sum(preds, axis=0) >= (len(models)/2)).astype(int)

def ensemble_proba(models, X):
    return np.mean([m.predict_proba(X)[:,1] for m in models], axis=0)

def feature_importance_ensemble(models, num_features, cat_features):
    ohe = models[0].named_steps["prep"].named_transformers_["cat"]
    cat_names = ohe.get_feature_names_out(cat_features)
    all_names = num_features + list(cat_names)
    imps = np.mean([m.named_steps["rf"].feature_importances_ for m in models], axis=0)
    order = np.argsort(imps)[::-1]
    return [(all_names[i], imps[i]) for i in order]

# ================================
# Experiment Runner
# ================================
def run_experiment(X, y, label="With Lat/Long/Year"):
    print(f"\n=== {label} ===")
    preprocessor, numf, catf = make_preprocessor(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    # ----- RandomForest Ensemble -----
    ensemble_models = create_ensemble(X_train, y_train, preprocessor)
    y_pred = ensemble_predict(ensemble_models, X_test)
    y_proba = ensemble_proba(ensemble_models, X_test)
    print("\n[RandomForest Ensemble]")
    print(classification_report(y_test, y_pred, digits=3))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("ROC-AUC:", roc_auc_score(y_test, y_proba))

    # Feature importance
    imps = feature_importance_ensemble(ensemble_models, numf, catf)
    print("\nTop 10 Feature Importances:")
    for feat, val in imps[:10]:
        print(f"{feat:30s} {val:.3f}")

    # ----- Logistic Regression -----
    logreg = Pipeline([
        ("prep", preprocessor),
        ("clf", LogisticRegression(max_iter=2000, class_weight="balanced", solver="lbfgs"))
    ])
    logreg.fit(X_train, y_train)
    y_pred_lr = logreg.predict(X_test)
    y_proba_lr = logreg.predict_proba(X_test)[:,1]
    print("\n[Logistic Regression]")
    print(classification_report(y_test, y_pred_lr, digits=3))
    print("ROC-AUC:", roc_auc_score(y_test, y_proba_lr))

    # ----- XGBoost -----
    xgb = Pipeline([
        ("prep", preprocessor),
        ("clf", XGBClassifier(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=5,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            use_label_encoder=False,
            eval_metric="logloss"
        ))
    ])
    xgb.fit(X_train, y_train)
    y_pred_xgb = xgb.predict(X_test)
    y_proba_xgb = xgb.predict_proba(X_test)[:,1]
    print("\n[XGBoost]")
    print(classification_report(y_test, y_pred_xgb, digits=3))
    print("ROC-AUC:", roc_auc_score(y_test, y_proba_xgb))

# Run Experiments (with and without Lat/Long/Year)

run_experiment(X, y, "With Lat/Long/Year")

drop_cols = ["Latitude", "Longitude", "Year_final"]
X2 = X.drop(columns=drop_cols)
run_experiment(X2, y, "Without Lat/Long/Year")












!pip install imbalanced-learn



import pandas as pd

# Read the source CSV file
df = pd.read_csv('uncleaned_ml_neg_1.csv', index_col=0)

# Sample 241 random rows and reset index in one line
random_sample = df.sample(n=241, random_state=42).reset_index(drop=True)

# Save the random sample to a new CSV file
random_sample.to_csv('uncleaned_ml_neg_1_1st.csv', index=False)

print(f"Successfully copied {len(random_sample)} random rows to uncleaned_ml_neg_1_1st.csv")
print(f"Original dataset had {len(df)} rows")


random_sample





# === GLOF ML: combine CSVs, preprocess, train LR / RF / XGBoost, report metrics ===
# Expects these files in the SAME FOLDER as this notebook:
#   uncleaned_ml_pos_1.csv        (positives, 241 rows)
#   uncleaned_ml_neg_1_1st.csv    (negatives, 241 rows)
#
# Outputs (same folder):
#   uncleaned_ml_1st.csv
#   preds_LogisticRegression.csv
#   preds_RandomForest.csv
#   preds_XGBoost.csv   (if xgboost installed)
#   model_metrics.csv

from pathlib import Path
import warnings
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    precision_score, recall_score, f1_score, roc_auc_score,
    confusion_matrix, classification_report
)

# Optional: XGBoost
try:
    from xgboost import XGBClassifier
    XGB_AVAILABLE = True
except Exception:
    XGB_AVAILABLE = False

warnings.filterwarnings("ignore")

HERE = Path(".").resolve()
POS_PATH = HERE / "uncleaned_ml_pos_1.csv"
NEG_PATH = HERE / "uncleaned_ml_neg_1_1st.csv"
COMBINED_OUT = HERE / "uncleaned_ml_1st.csv"

def load_and_prepare(pos_path: Path, neg_path: Path) -> pd.DataFrame:
    if not pos_path.exists() or not neg_path.exists():
        raise FileNotFoundError(f"Missing CSV(s):\n- {pos_path}\n- {neg_path}")

    pos = pd.read_csv(pos_path)
    neg = pd.read_csv(neg_path)

    # Drop accidental index cols like "Unnamed: 0"
    pos = pos.loc[:, ~pos.columns.str.contains(r"^Unnamed")]
    neg = neg.loc[:, ~neg.columns.str.contains(r"^Unnamed")]

    # Create/normalize target column
    if "GLOF" not in pos.columns:
        pos["GLOF"] = 1
    else:
        pos["GLOF"] = (pos["GLOF"] > 0).astype(int)

    if "GLOF" not in neg.columns:
        neg["GLOF"] = 0
    else:
        neg["GLOF"] = (neg["GLOF"] > 0).astype(int)

    # Debug source (removed from features later)
    pos["__source__"] = "pos"
    neg["__source__"] = "neg"

    # Column-union alignment (handles schema mismatches)
    all_cols = sorted(set(pos.columns) | set(neg.columns))
    pos = pos.reindex(columns=all_cols)
    neg = neg.reindex(columns=all_cols)

    df = pd.concat([pos, neg], ignore_index=True)
    df.to_csv(COMBINED_OUT, index=False)
    print(f"‚úÖ Combined saved ‚Üí {COMBINED_OUT}  shape={df.shape}")
    print("Class counts:\n", df["GLOF"].value_counts(dropna=False))
    return df

def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:
    cols = [c for c in X.columns if c != "__source__"]
    Xw = X[cols]

    num_cols = Xw.select_dtypes(include=["number"]).columns.tolist()
    cat_cols = Xw.select_dtypes(include=["object", "category", "bool"]).columns.tolist()

    num_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median", add_indicator=True)),  # automatic imputer (+missing flags)
        ("scale",   RobustScaler())                                         # outlier-robust scaler
    ])
    cat_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("ohe",     OneHotEncoder(drop="first", handle_unknown="ignore"))   # one-hot encoder
    ])

    return ColumnTransformer(
        transformers=[
            ("num", num_pipe, num_cols),
            ("cat", cat_pipe, cat_cols),
        ],
        remainder="drop",
        verbose_feature_names_out=False
    )

def train_and_eval(df: pd.DataFrame, target="GLOF", test_size=0.2, seed=42):
    df = df.dropna(subset=[target]).copy()
    X = df.drop(columns=[target, "__source__"], errors="ignore")
    y = df[target].astype(int)

    Xtr, Xte, ytr, yte = train_test_split(
        X, y, test_size=test_size, stratify=y, random_state=seed
    )

    pre = build_preprocessor(Xtr)

    models = {}

    # Logistic Regression (class_weight to be safe)
    models["LogisticRegression"] = Pipeline([
        ("pre", pre),
        ("clf", LogisticRegression(
            solver="liblinear", penalty="l2",
            class_weight="balanced",
            max_iter=2000, random_state=seed
        ))
    ])

    # Random Forest
    models["RandomForest"] = Pipeline([
        ("pre", pre),
        ("clf", RandomForestClassifier(
            n_estimators=500,
            class_weight="balanced_subsample",
            random_state=seed, n_jobs=-1
        ))
    ])

    # XGBoost (if available)
    if XGB_AVAILABLE:
        pos = int((ytr == 1).sum()); neg = int((ytr == 0).sum())
        spw = max(1.0, neg / max(1, pos))
        models["XGBoost"] = Pipeline([
            ("pre", pre),
            ("clf", XGBClassifier(
                n_estimators=500, learning_rate=0.05, max_depth=6,
                subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,
                eval_metric="logloss", random_state=seed, n_jobs=-1,
                scale_pos_weight=spw
            ))
        ])
    else:
        print("‚ÑπÔ∏è xgboost not installed; skipping.")

    rows = []
    for name, pipe in models.items():
        print(f"\n‚ñ∂Ô∏è Training {name} ...")
        pipe.fit(Xtr, ytr)
        yhat = pipe.predict(Xte)

        # probs for ROC-AUC if supported
        try:
            yproba = pipe.predict_proba(Xte)[:, 1]
            roc = roc_auc_score(yte, yproba)
        except Exception:
            yproba = None
            roc = np.nan

        prec = precision_score(yte, yhat, zero_division=0)
        rec  = recall_score(yte, yhat, zero_division=0)
        f1   = f1_score(yte, yhat, zero_division=0)
        cm   = confusion_matrix(yte, yhat)

        print(f"{name} ‚Äî classification report:\n{classification_report(yte, yhat, digits=3, zero_division=0)}")
        tn, fp, fn, tp = cm.ravel()
        print(f"{name} ‚Äî confusion matrix (rows=true, cols=pred):\n[[TN={tn}, FP={fp}],\n [FN={fn}, TP={tp}]]")

        # Save predictions
        out = pd.DataFrame({"y_true": yte.values, "y_pred": yhat})
        if yproba is not None: out["y_proba"] = yproba
        out_path = HERE / f"preds_{name}.csv"
        out.to_csv(out_path, index=False)
        print(f"üíæ Saved predictions ‚Üí {out_path}")

        rows.append({"model": name, "precision": prec, "recall": rec, "f1": f1, "roc_auc": roc, "test_n": len(yte)})

    metrics = pd.DataFrame(rows).sort_values(["recall","f1","precision"], ascending=False).reset_index(drop=True)
    metrics_path = HERE / "model_metrics.csv"
    metrics.to_csv(metrics_path, index=False)
    print(f"\n‚úÖ Metrics saved ‚Üí {metrics_path}\n{metrics}")
    return metrics

# Run
df = load_and_prepare(POS_PATH, NEG_PATH)
_ = train_and_eval(df, target="GLOF", test_size=0.2, seed=42)




